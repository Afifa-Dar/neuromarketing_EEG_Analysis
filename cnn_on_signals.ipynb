{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5af0fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a60c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc33f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1820867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'modified_data/'\n",
    "# like_samples = []\n",
    "# dislike_samples = []\n",
    "# labels = []\n",
    "# for filename in os.scandir(directory):\n",
    "#     data = pd.read_csv(filename.path)\n",
    "#     if (data[\"label\"][0] == 'Like'):\n",
    "#         labels.append(0)\n",
    "#         like_samples.append(data.drop(['label'] , axis = 1))\n",
    "#     else:\n",
    "#         labels.append(1)\n",
    "#         dislike_samples.append(data.drop(['label'] , axis = 1))\n",
    "    \n",
    "directory = 'modified_data/'\n",
    "samples = []\n",
    "labels = []\n",
    "for filename in os.scandir(directory):\n",
    "    data = pd.read_csv(filename.path)\n",
    "    samples.append(data.drop(['label'] , axis = 1))\n",
    "    if (data[\"label\"][0] == 'Like'):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e285364",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cb79355",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_samples = np.array(like_samples)\n",
    "dislike_samples = np.array(dislike_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb1401a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(461, 512, 14) (584, 512, 14)\n"
     ]
    }
   ],
   "source": [
    "print(like_samples.shape , dislike_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a366fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_like_size = int(len(like_samples) * 0.7)\n",
    "# test_like_size = len(like_labels) - train_like_size\n",
    "\n",
    "train_dislike_size = int(len(dislike_samples) * 0.7)\n",
    "# test_dislike_size =len(dislike_labels)  - train_dislike_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d50685e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "print(train_like_size )\n",
    "print(train_dislike_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9236a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use stratified sampling to randomly select samples for the train and test sets\n",
    "X_train_like, X_test_like, y_train_like, y_test_like = train_test_split(\n",
    "   like_samples, [i for i in labels if i == 0],\n",
    "    train_size=train_like_size )\n",
    " \n",
    "X_train_dislike, X_test_dislike, y_train_dislike, y_test_dislike = train_test_split(\n",
    "    dislike_samples, [i for i in labels if i == 1] , \n",
    "    train_size = train_dislike_size)\n",
    "\n",
    "# Combine the selected samples to form the train and test sets\n",
    "X_train = np.concatenate((X_train_like, X_train_dislike))\n",
    "X_test = np.concatenate((X_test_like, X_test_dislike))\n",
    "y_train = np.concatenate((y_train_like, y_train_dislike))\n",
    "y_test = np.concatenate((y_test_like, y_test_dislike))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b1e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.concatenate((like_samples[41:], dislike_samples[42:]))\n",
    "# X_test = np.concatenate((like_samples[:41], dislike_samples[:42]))\n",
    "# y_train = np.concatenate(([0]*420, [1] * 542))\n",
    "# y_test = np.concatenate(([0]*41, [1] * 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12a01d",
   "metadata": {},
   "source": [
    "# save train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d630bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('training-testing-data/testing/test_data', X_test, allow_pickle=True, fix_imports=True)\n",
    "# np.save('training-testing-data/testing/test_label', y_test, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "# np.save('training-testing-data/training/train_data', X_train, allow_pickle=True, fix_imports=True)\n",
    "# np.save('training-testing-data/training/train_label', y_train, allow_pickle=True, fix_imports=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e481515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape for CNN\n",
    "\n",
    "input_shape = (512,14,1)\n",
    "\n",
    "# Define CNN model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu' , input_shape = input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(164, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Dense(164, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(164, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# model.add(Dense(uni(ts=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "701ef020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3561eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 5s 97ms/step - loss: 1.3696 - accuracy: 0.5507\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.6663 - accuracy: 0.6849\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.4456 - accuracy: 0.7877\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.3863 - accuracy: 0.8288\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2638 - accuracy: 0.8890\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 4s 87ms/step - loss: 0.2209 - accuracy: 0.9164\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1533 - accuracy: 0.9411\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 4s 87ms/step - loss: 0.1548 - accuracy: 0.9397\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.1252 - accuracy: 0.9562\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 5s 119ms/step - loss: 0.1180 - accuracy: 0.9589\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.0851 - accuracy: 0.9712\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 0.0897 - accuracy: 0.9685\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 0.0598 - accuracy: 0.9877\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.0577 - accuracy: 0.9808\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0531 - accuracy: 0.9877\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 5s 110ms/step - loss: 0.0380 - accuracy: 0.9918\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 5s 109ms/step - loss: 0.0427 - accuracy: 0.9890\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 0.0351 - accuracy: 0.9945\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 5s 112ms/step - loss: 0.0317 - accuracy: 0.9918\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 5s 111ms/step - loss: 0.0289 - accuracy: 0.9904\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.0235 - accuracy: 0.9945\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 5s 109ms/step - loss: 0.0265 - accuracy: 0.9918\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 5s 110ms/step - loss: 0.0165 - accuracy: 0.9973\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.0280 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0172 - accuracy: 0.9959\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.0198 - accuracy: 0.9959\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.0291 - accuracy: 0.9932\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 0.0112 - accuracy: 0.9986\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 0.0164 - accuracy: 0.9973\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0141 - accuracy: 0.9986\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0195 - accuracy: 0.9932\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 5s 110ms/step - loss: 0.0141 - accuracy: 0.9973\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 5s 106ms/step - loss: 0.0099 - accuracy: 0.9986\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0116 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 5s 111ms/step - loss: 0.0092 - accuracy: 0.9986\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 6s 120ms/step - loss: 0.0084 - accuracy: 0.9986\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.0174 - accuracy: 0.9932\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.0138 - accuracy: 0.9973\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 5s 113ms/step - loss: 0.0127 - accuracy: 0.9973\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 0.0102 - accuracy: 0.9959\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 0.0130 - accuracy: 0.9932\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0073 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21fbeaac9d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train , epochs = 50 , batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "957873c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13dffdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting foolbox\n",
      "  Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (1.20.1)\n",
      "Collecting eagerpy>=0.30.0\n",
      "  Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (52.0.0.post20210125)\n",
      "Requirement already satisfied: GitPython>=3.0.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (3.1.31)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (4.7.1)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from foolbox) (2.25.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from GitPython>=3.0.7->foolbox) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.24.0->foolbox) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.24.0->foolbox) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.24.0->foolbox) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.24.0->foolbox) (4.0.0)\n",
      "Installing collected packages: eagerpy, foolbox\n",
      "Successfully installed eagerpy-0.30.0 foolbox-3.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dadf2609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "\n",
    "for data in X_test:\n",
    "    y_pred.append(np.argmax(model.predict(np.array([data , ]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e9a12",
   "metadata": {},
   "source": [
    "# evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529aa9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ee792d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Like','Dislike'],\n",
    "            yticklabels=['Like','Dislike'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8b69d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuaracy = (cm[0][0] + cm[1][1]) / X_test.shape[0] *100\n",
    "recall = (cm[0][0]) /(cm[0][0] + cm[1][0]) *100\n",
    "precision = (cm[0][0]) /(cm[0][0] + cm[0][1]) *100\n",
    "f1_score = (2*recall*precision)/(recall + precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c186422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  75.55555555555556\n",
      "Precision:  70.50359712230215\n",
      "Recall:  73.13432835820896\n",
      "F1 SCore:  71.7948717948718\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' , accuaracy)\n",
    "print('Precision: ' , precision)\n",
    "print('Recall: ' , recall)\n",
    "print('F1 SCore: ' , f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee3647",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c204219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/modified_data_single_fold\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/modified_data_single_fold\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/modified_data_single_fold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e566df1",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40261e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/modified_data_single_fold//')\n",
    "\n",
    "# Check its architecture\n",
    "# new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd321bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 44ms/step - loss: 0.2383 - accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23828691244125366, 0.9263157844543457]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate((np.concatenate((X_train,X_test))),np.concatenate((y_train,y_test)))\n",
    "model.evaluate(samples,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e242004",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-f60fae1a43d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Generate adversarial examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0madversarials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Evaluate the attack success\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\foolbox\\attacks\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mverify_input_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\foolbox\\attacks\\base.py\u001b[0m in \u001b[0;36mverify_input_bounds\u001b[1;34m(input, model)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mverify_input_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;31m# verify that input to the attack lies within model's input bounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import foolbox\n",
    "\n",
    "\n",
    "\n",
    "# Convert the TensorFlow model to a Foolbox model\n",
    "fmodel = foolbox.models.TensorFlowModel(model, bounds=(0, 255))\n",
    "#normalize samples\n",
    "samples = samples/255.0\n",
    "# Select the attack method (FGSM)\n",
    "attack = foolbox.attacks.FGSM()\n",
    "\n",
    "# Define the epsilon value for the attack\n",
    "epsilons = [0.1]  # Adjust the epsilon value based on your requirements\n",
    "\n",
    "# Generate adversarial examples\n",
    "adversarials = attack(fmodel,samples, labels, epsilons=epsilons)\n",
    "\n",
    "# Evaluate the attack success\n",
    "predictions = np.argmax(fmodel.predictions(adversarials), axis=1)\n",
    "accuracy = np.sum(predictions ==labels) / len(labels)\n",
    "print(\"Attack success rate: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a513ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack success rate: 55.89%\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "\n",
    "\n",
    "# Create an ART classifier wrapper for the model\n",
    "classifier = TensorFlowV2Classifier(model=model, \n",
    "                                    input_shape=(512, 14, 1), \n",
    "                                    nb_classes=2, \n",
    "                                    loss_object=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "\n",
    "# Select the attack method (FGSM)\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv = attack.generate(samples)\n",
    "\n",
    "# Evaluate the attack success\n",
    "predictions = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "accuracy = np.sum(predictions == labels) / len(labels)\n",
    "print(\"Attack success rate: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3dd261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
