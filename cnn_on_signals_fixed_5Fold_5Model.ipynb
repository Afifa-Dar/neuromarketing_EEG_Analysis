{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5af0fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a60c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1820867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'modified_data/'\n",
    "\n",
    "eeg_data = []\n",
    "labels = []\n",
    "for filename in os.scandir(directory):\n",
    "    data = pd.read_csv(filename.path)\n",
    "    if (data[\"label\"][0] == 'Like'):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "    eeg_data.append(data.drop(['label'] , axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3629909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 (1045, 512, 14)\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "eeg_data = np.array(eeg_data)\n",
    "print(len(labels) , eeg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61cd7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = eeg_data[:83]\n",
    "test_label = labels[:83]\n",
    "\n",
    "eeg_data = eeg_data[83:]\n",
    "labels = labels[83:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ece0b40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 512, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e481515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape for CNN\n",
    "def init_model(): \n",
    "    input_shape = (512,14,1)\n",
    "\n",
    "    # Define CNN model architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu' , input_shape = input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(164, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f473df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "k_fold = list(kfold.split(eeg_data , labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd1121a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60f1a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d38f783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "49/49 [==============================] - 7s 103ms/step - loss: 1.1213 - accuracy: 0.5579\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.6211 - accuracy: 0.7035\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.4645 - accuracy: 0.7867\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.3669 - accuracy: 0.8466\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.2517 - accuracy: 0.8908\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.1959 - accuracy: 0.9272\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.1875 - accuracy: 0.9233\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.1387 - accuracy: 0.9454\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.1219 - accuracy: 0.9597\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 0.1070 - accuracy: 0.9636\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0934 - accuracy: 0.9701\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0694 - accuracy: 0.9818\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0540 - accuracy: 0.9844\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0755 - accuracy: 0.9792\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0647 - accuracy: 0.9740\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0496 - accuracy: 0.9896\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0330 - accuracy: 0.9935\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0456 - accuracy: 0.9883\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0377 - accuracy: 0.9922\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0317 - accuracy: 0.9909\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0478 - accuracy: 0.9844\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0607 - accuracy: 0.9779\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0319 - accuracy: 0.9922\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0230 - accuracy: 0.9961\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0306 - accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 6s 110ms/step - loss: 0.0204 - accuracy: 0.9974\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0158 - accuracy: 0.9974\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0219 - accuracy: 0.9974\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.0101 - accuracy: 0.9987\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0344 - accuracy: 0.9896\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 7s 148ms/step - loss: 0.0215 - accuracy: 0.9961\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0219 - accuracy: 0.9896\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0255 - accuracy: 0.9896\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0186 - accuracy: 0.9935\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0120 - accuracy: 0.9974\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0308 - accuracy: 0.9909\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0288 - accuracy: 0.9883\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0450 - accuracy: 0.9844\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0126 - accuracy: 0.9974\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0087 - accuracy: 0.9987\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0090 - accuracy: 0.9987\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0078 - accuracy: 0.9987\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 0.0072 - accuracy: 0.9987\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0072 - accuracy: 0.9987\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 7s 150ms/step - loss: 0.0137 - accuracy: 0.9948\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0119 - accuracy: 0.9974\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 7s 148ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0197 - accuracy: 0.9961\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.0073 - accuracy: 0.9987\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.0075 - accuracy: 0.9987\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0040 - accuracy: 0.9974\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 0.0092 - accuracy: 0.9974\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0139 - accuracy: 0.9948\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0256 - accuracy: 0.9883\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 6s 111ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0066 - accuracy: 0.9974\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0062 - accuracy: 0.9974\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0100 - accuracy: 0.9974\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0073 - accuracy: 0.9974\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 7s 151ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0101 - accuracy: 0.9974\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0043 - accuracy: 0.9974\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0158 - accuracy: 0.9961\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0076 - accuracy: 0.9987\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 6s 111ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0149 - accuracy: 0.9961\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0049 - accuracy: 0.9974\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 0.0045 - accuracy: 0.9974\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0095 - accuracy: 0.9948\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0171 - accuracy: 0.9948\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0122 - accuracy: 0.9948\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0059 - accuracy: 0.9974\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0052 - accuracy: 0.9974\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0109 - accuracy: 0.9948\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 6s 129ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 7.0577e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 7.4559e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 6.6977e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0110 - accuracy: 0.9961\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0094 - accuracy: 0.9987\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0239 - accuracy: 0.9948\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0063 - accuracy: 0.9974\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 9.6476e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0332 - accuracy: 0.9922\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 6s 111ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 5.6243e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 3.6381e-04 - accuracy: 1.0000\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 7s 147ms/step - loss: 2.6017e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 6.1188e-04 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 4.5575e-04 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 4.5852e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 5.0460e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 4.4520e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 2.7462e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 0.0033 - accuracy: 0.9974\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0066 - accuracy: 0.9974\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0132 - accuracy: 0.9948\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0109 - accuracy: 0.9948\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 3.0499e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 7s 153ms/step - loss: 9.2018e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 7.8384e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 7.0682e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 7.3631e-04 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 1.9882e-04 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 9.3611e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 3.3588e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 3.0615e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 1.6147e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 1.5101e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 2.4905e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 5.4161e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 7s 151ms/step - loss: 2.4609e-04 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 6s 129ms/step - loss: 0.0064 - accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 0.0028 - accuracy: 0.9974\n",
      "1\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 3.1362 - accuracy: 0.6166\n",
      "Epoch 1/200\n",
      "49/49 [==============================] - 8s 126ms/step - loss: 1.2048 - accuracy: 0.5670\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 0.6184 - accuracy: 0.7386\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 0.4169 - accuracy: 0.8010\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 0.3306 - accuracy: 0.8479\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 0.2403 - accuracy: 0.9038\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.2103 - accuracy: 0.9129\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.1550 - accuracy: 0.9454\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.1419 - accuracy: 0.9480\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.1313 - accuracy: 0.9545\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 7s 140ms/step - loss: 0.1037 - accuracy: 0.9649\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 7s 148ms/step - loss: 0.1126 - accuracy: 0.9649\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 0.0835 - accuracy: 0.9792\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.0673 - accuracy: 0.9740\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 0.0545 - accuracy: 0.9818\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 11s 230ms/step - loss: 0.0588 - accuracy: 0.9857\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 0.0589 - accuracy: 0.9844\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 0.0518 - accuracy: 0.9818\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 9s 174ms/step - loss: 0.0357 - accuracy: 0.9909\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.0358 - accuracy: 0.9870\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.0315 - accuracy: 0.9935\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 0.0246 - accuracy: 0.9948\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 0.0259 - accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 9s 174ms/step - loss: 0.0258 - accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 0.0160 - accuracy: 0.9987\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 9s 173ms/step - loss: 0.0192 - accuracy: 0.9961\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 0.0123 - accuracy: 0.9987\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0158 - accuracy: 0.9961\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0214 - accuracy: 0.9948\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0174 - accuracy: 0.9987\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 0.0131 - accuracy: 0.9987\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 8s 172ms/step - loss: 0.0196 - accuracy: 0.9948\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 8s 169ms/step - loss: 0.0101 - accuracy: 0.9987\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 8s 169ms/step - loss: 0.0133 - accuracy: 0.9987\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.0096 - accuracy: 0.9987\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 9s 184ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 9s 173ms/step - loss: 0.0147 - accuracy: 0.9987\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 9s 173ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 0.0139 - accuracy: 0.9974\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 0.0178 - accuracy: 0.9948\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 8s 174ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0130 - accuracy: 0.9961\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 7s 141ms/step - loss: 0.0228 - accuracy: 0.9935\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0201 - accuracy: 0.9948\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0104 - accuracy: 0.9987\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.0063 - accuracy: 0.9974\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0108 - accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0214 - accuracy: 0.9896\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0109 - accuracy: 0.9948\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0069 - accuracy: 0.9974\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0092 - accuracy: 0.9961\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 8s 166ms/step - loss: 0.0134 - accuracy: 0.9948\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 9s 184ms/step - loss: 0.0102 - accuracy: 0.9974\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 8s 159ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0064 - accuracy: 0.9961\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 6s 129ms/step - loss: 0.0358 - accuracy: 0.9948\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 7s 153ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 9s 185ms/step - loss: 0.0117 - accuracy: 0.9974\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 8s 162ms/step - loss: 0.0120 - accuracy: 0.9948\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 8s 165ms/step - loss: 0.0035 - accuracy: 0.9974\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 8s 161ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 8s 165ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0156 - accuracy: 0.9974\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 7s 140ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 9.9297e-04 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 8s 167ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 8s 174ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 7s 154ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 7s 154ms/step - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 0.0034 - accuracy: 0.9974\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 7s 154ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 3.7752e-04 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 6.9721e-04 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 7s 141ms/step - loss: 7.0991e-04 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 8s 159ms/step - loss: 0.0200 - accuracy: 0.9948\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 6s 132ms/step - loss: 0.0085 - accuracy: 0.9987\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 6s 129ms/step - loss: 6.2438e-04 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 8s 162ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 7s 153ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 7s 132ms/step - loss: 0.0144 - accuracy: 0.9974\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 0.0070 - accuracy: 0.9974\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 8s 160ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.0103 - accuracy: 0.9948\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 7s 140ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 7s 140ms/step - loss: 0.0020 - accuracy: 0.9987\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 7s 150ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 8s 160ms/step - loss: 0.0371 - accuracy: 0.9909\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 7s 150ms/step - loss: 4.0709e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 8.1954e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0071 - accuracy: 0.9987\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 5.1410e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 7s 150ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 4.4354e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 5.1388e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 8s 168ms/step - loss: 9.9151e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0239 - accuracy: 0.9909\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0299 - accuracy: 0.9922\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 9s 184ms/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 8s 168ms/step - loss: 0.0194 - accuracy: 0.9961\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.0252 - accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 8s 169ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 8s 174ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 9s 187ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 5.8640e-04 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 8s 171ms/step - loss: 7.5387e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 8s 166ms/step - loss: 3.7608e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 2.2819e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 7.3004e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 3.5291e-04 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 5.1496e-04 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 1.8943e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 4.4809e-04 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 3.2039e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 8.0546e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0097 - accuracy: 0.9987\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 7.6301e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 4.7396e-04 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0105 - accuracy: 0.9974\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 9.0732e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 3.6266e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 3.9109e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 5.6622e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0088 - accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0043 - accuracy: 0.9974\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 2.1707e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 4.5920e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 6s 122ms/step - loss: 8.6366e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 9.8240e-04 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 6.7555e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "2\n",
      "7/7 [==============================] - 1s 64ms/step - loss: 2.1396 - accuracy: 0.6321\n",
      "Epoch 1/200\n",
      "49/49 [==============================] - 6s 108ms/step - loss: 1.2315 - accuracy: 0.5662\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.6812 - accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.4701 - accuracy: 0.7935\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.3563 - accuracy: 0.8429\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.3122 - accuracy: 0.8662\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.2269 - accuracy: 0.9104\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.1957 - accuracy: 0.9234\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.1616 - accuracy: 0.9377\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.1266 - accuracy: 0.9610\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.1014 - accuracy: 0.9649\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0917 - accuracy: 0.9740\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0646 - accuracy: 0.9818\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0833 - accuracy: 0.9727\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0615 - accuracy: 0.9844\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0727 - accuracy: 0.9779\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 0.0543 - accuracy: 0.9857\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0466 - accuracy: 0.9831\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0375 - accuracy: 0.9896\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 0.0249 - accuracy: 0.9987\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 0.0259 - accuracy: 0.9974\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0228 - accuracy: 0.9974\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 6s 111ms/step - loss: 0.0210 - accuracy: 0.9961\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0287 - accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0247 - accuracy: 0.9961\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0215 - accuracy: 0.9948\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0104 - accuracy: 0.9987\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0181 - accuracy: 0.9948\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0189 - accuracy: 0.9961\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0103 - accuracy: 0.9974\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0202 - accuracy: 0.9922\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0130 - accuracy: 0.9974\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0122 - accuracy: 0.9974\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0102 - accuracy: 0.9987\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0080 - accuracy: 0.9974\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0124 - accuracy: 0.9948\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0087 - accuracy: 0.9987\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0155 - accuracy: 0.9961\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0313 - accuracy: 0.9883\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0163 - accuracy: 0.9961\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0126 - accuracy: 0.9974\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0107 - accuracy: 0.9948\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0075 - accuracy: 0.9987\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0083 - accuracy: 0.9987\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 6s 124ms/step - loss: 0.0120 - accuracy: 0.9974\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0073 - accuracy: 0.9961\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0091 - accuracy: 0.9987\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0074 - accuracy: 0.9974\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0181 - accuracy: 0.9909\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.0123 - accuracy: 0.9948\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0074 - accuracy: 0.9987\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0109 - accuracy: 0.9974\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 6s 121ms/step - loss: 0.0104 - accuracy: 0.9974\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0089 - accuracy: 0.9987\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0505 - accuracy: 0.9831\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0096 - accuracy: 0.9948\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0057 - accuracy: 0.9974\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0101 - accuracy: 0.9948\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 5.3812e-04 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0099 - accuracy: 0.9948\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0062 - accuracy: 0.9974\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0046 - accuracy: 0.9974\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0065 - accuracy: 0.9974\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0123 - accuracy: 0.9987\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0056 - accuracy: 0.9974\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0105 - accuracy: 0.9948\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0080 - accuracy: 0.9987\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 6.1457e-04 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 6.1891e-04 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 7.7574e-04 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 4.4308e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 5.4802e-04 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 4.0316e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 4.7696e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 3.8028e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 4.5687e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 5.2659e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 7.5671e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 6.0520e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0082 - accuracy: 0.9987\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 8.7404e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0128 - accuracy: 0.9987\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0018 - accuracy: 0.9987\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0017 - accuracy: 0.9987\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0088 - accuracy: 0.9987\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0065 - accuracy: 0.9974\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0060 - accuracy: 0.9974\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0020 - accuracy: 0.9987\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 7.3613e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 8.6226e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 4.3475e-04 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 4.2422e-04 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 6.0842e-04 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 4.8269e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 4.0188e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 4.2596e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 4.2137e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 2.5247e-04 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 5.6211e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0063 - accuracy: 0.9974\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0058 - accuracy: 0.9961\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0121 - accuracy: 0.9974\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 3.3634e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 2.7091e-04 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 6.2656e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 5.1934e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0089 - accuracy: 0.9961\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0054 - accuracy: 0.9974\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0101 - accuracy: 0.9987\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0073 - accuracy: 0.9961\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 9.0291e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0094 - accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 6.3294e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 5.8208e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "3\n",
      "6/6 [==============================] - 1s 72ms/step - loss: 1.0907 - accuracy: 0.8021\n",
      "Epoch 1/200\n",
      "49/49 [==============================] - 6s 106ms/step - loss: 1.2472 - accuracy: 0.5325\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.6651 - accuracy: 0.6468\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.4523 - accuracy: 0.7701\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.3779 - accuracy: 0.8416\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.3219 - accuracy: 0.8481\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.2553 - accuracy: 0.9091\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.2107 - accuracy: 0.9286\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.1620 - accuracy: 0.9481\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.1319 - accuracy: 0.9545\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.1430 - accuracy: 0.9442\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.1182 - accuracy: 0.9597\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.1045 - accuracy: 0.9701\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0634 - accuracy: 0.9844\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0788 - accuracy: 0.9740\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0439 - accuracy: 0.9961\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0625 - accuracy: 0.9818\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.1133 - accuracy: 0.9623\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0458 - accuracy: 0.9870\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0397 - accuracy: 0.9909\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0481 - accuracy: 0.9857\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0290 - accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0229 - accuracy: 0.9961\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0231 - accuracy: 0.9935\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 5s 100ms/step - loss: 0.0201 - accuracy: 0.9974\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0580 - accuracy: 0.9831\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.1152 - accuracy: 0.9558\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0359 - accuracy: 0.9883\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0199 - accuracy: 0.9987\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0144 - accuracy: 0.9987\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0153 - accuracy: 0.9987\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0121 - accuracy: 0.9987\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0160 - accuracy: 0.9961\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0124 - accuracy: 0.9974\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 5s 101ms/step - loss: 0.0101 - accuracy: 0.9974\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0110 - accuracy: 0.9987\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0092 - accuracy: 0.9961\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0101 - accuracy: 0.9987\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0100 - accuracy: 0.9961\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 0.0198 - accuracy: 0.9948\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 7s 140ms/step - loss: 0.0147 - accuracy: 0.9961\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 7s 144ms/step - loss: 0.0103 - accuracy: 0.9974\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 7s 147ms/step - loss: 0.0110 - accuracy: 0.9961\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 6s 123ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0099 - accuracy: 0.9974\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 0.0083 - accuracy: 0.9987\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 0.0087 - accuracy: 0.9987\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 0.0067 - accuracy: 0.9961\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 6s 129ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0058 - accuracy: 0.9974\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.0093 - accuracy: 0.9948\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 70/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 5s 110ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 7.7015e-04 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0055 - accuracy: 0.9974\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 5s 111ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 8.8929e-04 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 9.9213e-04 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 9.6011e-04 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 7.4794e-04 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 7.9395e-04 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0095 - accuracy: 0.9961\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0058 - accuracy: 0.9961\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 3.7886e-04 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 6.8670e-04 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 7.6477e-04 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 5.9391e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 8.2846e-04 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0059 - accuracy: 0.9974\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0137 - accuracy: 0.9974\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0094 - accuracy: 0.9961\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0132 - accuracy: 0.9948\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0265 - accuracy: 0.9922\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 8.4288e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0042 - accuracy: 0.9974\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 9.7385e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0025 - accuracy: 0.9987\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0061 - accuracy: 0.9987\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 8.5071e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 7.6212e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 5.7309e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0214 - accuracy: 0.9935\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0046 - accuracy: 0.9974\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0118 - accuracy: 0.9974\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0041 - accuracy: 0.9974\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.0042 - accuracy: 0.9974\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0075 - accuracy: 0.9974\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0104 - accuracy: 0.9974\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0050 - accuracy: 0.9974\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0035 - accuracy: 0.9974\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 8.4277e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0105 - accuracy: 0.9974\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 6.2053e-04 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0050 - accuracy: 0.9974\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0043 - accuracy: 0.9974\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 8.3094e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0141 - accuracy: 0.9987\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0158 - accuracy: 0.9948\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0073 - accuracy: 0.9987\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0040 - accuracy: 0.9974\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 6.1547e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 6.5120e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 9.6111e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0041 - accuracy: 0.9974\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 5.2110e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 5.1323e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0020 - accuracy: 0.9987\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 4.3712e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "4\n",
      "6/6 [==============================] - 1s 62ms/step - loss: 1.1696 - accuracy: 0.7292\n",
      "Epoch 1/200\n",
      "49/49 [==============================] - 6s 101ms/step - loss: 1.0745 - accuracy: 0.6143\n",
      "Epoch 2/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.6501 - accuracy: 0.7247\n",
      "Epoch 3/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.4263 - accuracy: 0.8065\n",
      "Epoch 4/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.3228 - accuracy: 0.8481\n",
      "Epoch 5/200\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 0.2475 - accuracy: 0.9013\n",
      "Epoch 6/200\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.1937 - accuracy: 0.9273\n",
      "Epoch 7/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.1843 - accuracy: 0.9312\n",
      "Epoch 8/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.1364 - accuracy: 0.9545\n",
      "Epoch 9/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.1369 - accuracy: 0.9532\n",
      "Epoch 10/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.1022 - accuracy: 0.9649\n",
      "Epoch 11/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0786 - accuracy: 0.9818\n",
      "Epoch 12/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0627 - accuracy: 0.9831\n",
      "Epoch 13/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0493 - accuracy: 0.9896\n",
      "Epoch 14/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0544 - accuracy: 0.9857\n",
      "Epoch 15/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0548 - accuracy: 0.9818\n",
      "Epoch 16/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0474 - accuracy: 0.9857\n",
      "Epoch 17/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 18/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0344 - accuracy: 0.9948\n",
      "Epoch 19/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0458 - accuracy: 0.9870\n",
      "Epoch 20/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0282 - accuracy: 0.9961\n",
      "Epoch 21/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0246 - accuracy: 0.9961\n",
      "Epoch 22/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0289 - accuracy: 0.9857\n",
      "Epoch 23/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0229 - accuracy: 0.9948\n",
      "Epoch 24/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0321 - accuracy: 0.9909\n",
      "Epoch 25/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0325 - accuracy: 0.9922\n",
      "Epoch 26/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0281 - accuracy: 0.9922\n",
      "Epoch 27/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "Epoch 28/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0264 - accuracy: 0.9935\n",
      "Epoch 29/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0151 - accuracy: 0.9974\n",
      "Epoch 30/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0209 - accuracy: 0.9948\n",
      "Epoch 31/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0219 - accuracy: 0.9948\n",
      "Epoch 32/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0155 - accuracy: 0.9974\n",
      "Epoch 33/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0101 - accuracy: 0.9987\n",
      "Epoch 34/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 36/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 37/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0122 - accuracy: 0.9974\n",
      "Epoch 38/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0074 - accuracy: 0.9987\n",
      "Epoch 39/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0103 - accuracy: 0.9974\n",
      "Epoch 40/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 41/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0087 - accuracy: 0.9974\n",
      "Epoch 42/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 45/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 54/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0168 - accuracy: 0.9948\n",
      "Epoch 55/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0167 - accuracy: 0.9948\n",
      "Epoch 56/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0199 - accuracy: 0.9961\n",
      "Epoch 57/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0494 - accuracy: 0.9883\n",
      "Epoch 58/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0107 - accuracy: 0.9974\n",
      "Epoch 59/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0083 - accuracy: 0.9987\n",
      "Epoch 60/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0176 - accuracy: 0.9922\n",
      "Epoch 61/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 62/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0265 - accuracy: 0.9948\n",
      "Epoch 63/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 64/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 65/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 68/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 69/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0175 - accuracy: 0.9974\n",
      "Epoch 71/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 72/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 73/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0253 - accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 75/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0070 - accuracy: 0.9961\n",
      "Epoch 77/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 9.2024e-04 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 82/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 83/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 85/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 86/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 91/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "49/49 [==============================] - 5s 107ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "Epoch 93/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0069 - accuracy: 0.9974\n",
      "Epoch 94/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0047 - accuracy: 0.9974\n",
      "Epoch 95/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0028 - accuracy: 0.9987\n",
      "Epoch 99/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 100/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 103/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 104/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0070 - accuracy: 0.9974\n",
      "Epoch 105/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 106/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 107/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 108/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 8.6255e-04 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 114/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 116/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 121/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 122/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 123/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 124/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 5.8992e-04 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 8.8710e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 7.6035e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 8.1646e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 6.1669e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 1.8092e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 134/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 7.3934e-04 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 5.1996e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 1.9459e-04 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 1.9274e-04 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 4.6682e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 6.0095e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 3.2529e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 2.3644e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 4.5900e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 3.4910e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 2.6000e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 1.0942e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 2.4090e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 2.2092e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "49/49 [==============================] - 5s 106ms/step - loss: 4.7503e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 5s 104ms/step - loss: 1.4810e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 1.9496e-04 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 3.4135e-04 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "49/49 [==============================] - 5s 105ms/step - loss: 2.6425e-04 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.0116 - accuracy: 0.9974\n",
      "Epoch 155/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0065 - accuracy: 0.9974\n",
      "Epoch 156/200\n",
      "49/49 [==============================] - 5s 103ms/step - loss: 0.0048 - accuracy: 0.9974\n",
      "Epoch 157/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0106 - accuracy: 0.9974\n",
      "Epoch 158/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0029 - accuracy: 0.9987\n",
      "Epoch 159/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0080 - accuracy: 0.9961\n",
      "Epoch 160/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0127 - accuracy: 0.9948\n",
      "Epoch 161/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 163/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 4.7973e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 3.0106e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 169/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 170/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 171/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 173/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 174/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0083 - accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 178/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0090 - accuracy: 0.9961\n",
      "Epoch 179/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0027 - accuracy: 0.9987\n",
      "Epoch 181/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 182/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 183/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0014 - accuracy: 0.9987\n",
      "Epoch 184/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 185/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 4.7183e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 2.6122e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0016 - accuracy: 0.9987\n",
      "Epoch 189/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 8.3253e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0022 - accuracy: 0.9987\n",
      "Epoch 191/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 4.3664e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0019 - accuracy: 0.9987\n",
      "Epoch 193/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 4.4739e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 2.8481e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 196/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 197/200\n",
      "49/49 [==============================] - 5s 99ms/step - loss: 2.5312e-04 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "49/49 [==============================] - 5s 97ms/step - loss: 0.0028 - accuracy: 0.9974\n",
      "Epoch 199/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 4.9443e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "49/49 [==============================] - 5s 98ms/step - loss: 8.4111e-04 - accuracy: 1.0000\n",
      "5\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.4764 - accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "testing_scores = []\n",
    "training_score = []\n",
    "for train_indices, test_indices in k_fold:\n",
    "    \n",
    "    X_train, X_test = eeg_data[train_indices], eeg_data[test_indices]\n",
    "    y_train, y_test = labels[train_indices], labels[test_indices]\n",
    "    \n",
    "#     train_0, train_1 = len(y_train[y_train==0]), len(y_train[y_train==1])\n",
    "#     test_0, test_1 = len(y_val[y_val==0]), len(y_val[y_val==1])\n",
    "#     print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n",
    "    \n",
    "    model = init_model()\n",
    "    # Train the model on the training data for this fold\n",
    "    history = model.fit(X_train, y_train, epochs = 200 , batch_size = 16)\n",
    "    count+=1\n",
    "    print(count)\n",
    "    training_score.append(history.history['accuracy'][-1] * 100)\n",
    "    folds.append(history)\n",
    "    \n",
    "    # Evaluate the model on the validation data for this fold\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    testing_scores.append(score[1] * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a640644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.65803074836731,\n",
       " 63.21243643760681,\n",
       " 80.20833134651184,\n",
       " 72.91666865348816,\n",
       " 72.91666865348816]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee878020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.73992109298706, 99.73992109298706, 99.8701274394989, 100.0, 100.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83235398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.callbacks.History at 0x17e673a4350>,\n",
       " <keras.src.callbacks.History at 0x17e573b4d90>,\n",
       " <keras.src.callbacks.History at 0x17e4b50ce10>,\n",
       " <keras.src.callbacks.History at 0x17e71e24e10>,\n",
       " <keras.src.callbacks.History at 0x17e000a7250>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "510f6835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average testing score: 70.18242716789246\n"
     ]
    }
   ],
   "source": [
    "avg_score = sum(testing_scores) / len(testing_scores)\n",
    "print('Average testing score:', avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "736c8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 1\n",
    "# co = 0\n",
    "# for i in folds:\n",
    "#     plt.figure(figsize = (12,8))\n",
    "#     plt.subplot(5,1,c)\n",
    "#     plt.plot(i.history['accuracy'], label='val_accuracy')\n",
    "# #     plt.plot(i.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0.5, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     c+=1\n",
    "#     co+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56b8ebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['1st_fold' , '2nd_fold' , '3rd_fold' , '4th_fold' , '5th_fold']\n",
    "barWidth = 0.25\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "br1 = np.arange(len(x))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "plt.bar(br1  , training_score[:5] , color = \"c\" , label = \"training accuracy\" ,width = barWidth)\n",
    "plt.bar(br2 , testing_scores[:5] , color = \"y\" , label = \"testing accuracy\" , width = barWidth)\n",
    "plt.xlabel('folds', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('accuracies', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(x))],x)\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aad13c",
   "metadata": {},
   "source": [
    "# ensambled the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e4eec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "WARNING:tensorflow:5 out of the last 415 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017E5C342700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 1, 0]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 1, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 0, 0, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 1, 1, 1, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 0, 0, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 1, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 1, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0, 1, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 1, 0, 1, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[1, 1, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 0, 1, 1, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 0, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 0, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 1, 0, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 0, 1, 1, 0]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 0, 1, 0]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[0, 0, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 0, 1, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 0, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 0, 1, 1, 0]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 1, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0, 0, 0, 0, 0]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[1, 0, 1, 1, 1]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for data in test_data:\n",
    "    res= []\n",
    "    for modl in folds[:5]:\n",
    "        res.append(np.argmax(modl.model.predict(np.array([data , ]))))\n",
    "    print(res)\n",
    "    \n",
    "    if res.count(0) > res.count(1):\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "        \n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db5c49",
   "metadata": {},
   "source": [
    "# Evaluate ensambeled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53bb719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14b42345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label,y_pred)\n",
    " \n",
    "#Plot the confusion matrix.\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Like','Dislike'],\n",
    "            yticklabels=['Like','Dislike'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5dcf01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuaracy = (cm[0][0] + cm[1][1]) / test_data.shape[0] *100\n",
    "recall = (cm[0][0]) /(cm[0][0] + cm[1][0]) *100\n",
    "precision = (cm[0][0]) /(cm[0][0] + cm[0][1]) *100\n",
    "f1_score = (2*recall*precision)/(recall + precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efcd1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.10843373493977\n",
      "Precision:  56.09756097560976\n",
      "Recall:  95.83333333333334\n",
      "F1 SCore:  70.76923076923077\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' , accuaracy)\n",
    "print('Precision: ' , precision)\n",
    "print('Recall: ' , recall)\n",
    "print('F1 SCore: ' , f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573891d",
   "metadata": {},
   "source": [
    "# save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9ff5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_fold = 1\n",
    "# for i in folds:\n",
    "#     i.model.save(f'models/modified-data-5Fold-5Model/fold_{num_fold}')\n",
    "#     num_fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3639d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97f79f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11a0dceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "        507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "        520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "        533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "        559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "        572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "        598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "        611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "        624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
       "        637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "        650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
       "        663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
       "        676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
       "        689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
       "        702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
       "        715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
       "        728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
       "        741, 742, 743, 744, 745, 752, 755, 756, 760, 762, 764, 766, 768,\n",
       "        775, 776, 778, 779, 780, 781, 782, 783, 785, 786, 787, 788, 790,\n",
       "        793, 796, 797]),\n",
       " array([746, 747, 748, 749, 750, 751, 753, 754, 757, 758, 759, 761, 763,\n",
       "        765, 767, 769, 770, 771, 772, 773, 774, 777, 784, 789, 791, 792,\n",
       "        794, 795, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808,\n",
       "        809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821,\n",
       "        822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834,\n",
       "        835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847,\n",
       "        848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860,\n",
       "        861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873,\n",
       "        874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886,\n",
       "        887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899,\n",
       "        900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912,\n",
       "        913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925,\n",
       "        926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938,\n",
       "        939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951,\n",
       "        952, 953, 954, 955, 956, 957, 958, 959, 960, 961]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "739420a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.callbacks.History at 0x17e673a4350>,\n",
       " <keras.src.callbacks.History at 0x17e573b4d90>,\n",
       " <keras.src.callbacks.History at 0x17e4b50ce10>,\n",
       " <keras.src.callbacks.History at 0x17e71e24e10>,\n",
       " <keras.src.callbacks.History at 0x17e000a7250>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9da7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
